2024.03.14. (목) 머신러닝 week 01

1. 머신러닝
    - 데이터에서 학습하도록 컴퓨터를 프로그래밍하는 과학(또는 예술) 
    - 기본용어
        > 훈련 세트 (training set) : 시스템이 학습하는데 사용하는 샘플
        > 훈련 사례 (trainging instance) or 샘플 (sample) : 각 훈련 데이터
        > 모델 (model) : 머신러닝 시스템에서 학습하고 예측을 만드는 부분
        > 신경망 (neural network), 랜덤 포레스트 (random forest)

        > 작업 T : 새로운 메일이 스팸인지 구분하는 것
        > 경험 E : 훈련 데이터 (training data)
        > 성능 측정 P : 직접 정의해야하며, 이 성능 측정을 정확도 (accuracy) 라고 부르며 분류 작업에 자주 사용

        *전통적 프로그래밍 기법으로는 규칙이 점점 길고 복잡해지므로 유지 보수하기 매우 힘듦
        *프로그램이 훨씬 짧아지고 유지 보수하기 쉬우며 대부분 정확도가 더 높음.
            - 기존 머신러닝 기법에 기반을 둔 스팸 필터는 일반 메일에 비해 스팸에 자주 나타나는 패턴을 감지하여 
              어떤 단어와 구절이 스팸 메일을 판단하는데 좋은 기준인지 자동으로 학습. 
    
            ^전통전인 접근 방법 1. 문제연구 > 규칙 작성 > 3. 평가 > 4.1. 오류분석 / 4.2. 론칭
            ^머신러닝 접근 방법 1. 문제연구 > 머신러닝 모델 훈련 > 3. 평가 > 4.1. 오류분석 / 4.2.론칭
    
        *자동으로 변화에 적응
            - 머신러닝 기반의 스팸 필터는 사용자가 스팸으로 지정한 메일에 유독 'For U'가 자주 나타나는 것을 자동으로 
              인식하고 별도의 작업을 하지 않아도 이 단어를 스팸으로 분류.
    
            ^자동으로 변화에 적응 1. 머신러닝 모델 훈련 > 2. 평가 > (자동화 가능) 3. 론칭 > 4. 데이터 업데이트 -- {데이터}
    
        *데이터 마이닝 (data mining) 
            - 대용량의 데이터를 분석하여 숨겨진 패턴을 발견
    
            ^머신러닝을 통해 학습 1. 문제 연구 > 2. 머신러닝 모델 훈련 > {솔루션} > 3. 솔루션 분석 > ! > 4. 문제에 대한 이해 증가 > 5. 필요하다면 반복

    - 머신러닝의 강점 분야 
        ●기존 솔루션으로는 많은 수동 조정과 규칙이 필요한 문제 
            > 머신러닝 모델이 코드를 간단하게 만들고 전통전인 방법보다 더 잘 수행.
        ●전통적인 방식으로는 해결 방법이 없는 복잡한 문제
            > 가장 뛰어난 머신러닝 기법으로 해결 방법을 찾음.
        ●유동적인 환경 ( 손뉴동ㅋㅋ? )
            > 머신러닝 시스템은 새로운 데이터로 쉽게 재훈련할 수 있어 항상 최신 상태를 유지
        ●복잡한 문제와 대량의 데이터에서 인사이트 얻기.

            *ex. week01.머신러닝개념 9p

2. 머신러닝 시스템의 종류
    - 넓은 범주의 분류
        > 훈련 지도 방식
            : 지도, 비지도, 준지도, 자기 지도, 강화 학습
        > 실시간으로 점진적인 학습을 할 수 있는지
            : 온라인 학습과 배치 학습
        > 단순하게 알고 있는 데이터 포인트와 새 데이터 포인트를 비교 또는 과학자들이 하는 것처럼 '훈련 데이터셋'에서 패턴을 
          발견하여 예측 모델을 생성.
            :사례 기반 학습과 모델 기반 학습

    ! 훈련 지도 방식
        : 머신러닝 시스템을 학습하는 동안의 지도 형태나 정보량에 따라 분류

    ! 지도 학습 (surpervised learning ) 
        : 알고리즘에 주입하는 훈련 데이터에 레이블 (label) 이라는 원하는 답이 포함.
            > 분류 (classification) - 스팸 필터
            > 특성 (feature) - <주행거리, 연식, 브랜드 등)을 사용해 중고차 가격 같은 타겟 (target) 수치를 예측
                ● 회귀 ( regression )
                (중간고사 정리 PPT 스팸 분류를 위한 레이블된 훈련 세트<지도 학습의 예>)
    -회귀 알고리즘을 분류에 사용할 수도 있음.
        ● 반대로 일부 분류 알고리즘을 회귀에 사용할 수도 있음.
            ex) 분류에 널리 쓰이는 로지스틱 회귀(logisitic regression)
                (회귀 문제: 주어진 입력 특성으로 값을 예측)
        > 비지도 학습 (unsupervised learning)
            : 훈련 데이터에 레이블이 없음
                > 시스템이 아무런 도움 없이 학습
                (비지도 학습에서 레이블이 없는 훈련세트)
            :계층 군집(hierarchical clustering)

            > 시각화(visualization)
            > 차원 축소(dimensionality reduction)
            > 특성 추출(feature extraction)
            > 이상치 탐지(outlier detection)
    - 배치 학습과 온라인 학습
        ● 배치 학습 (batch learning)
            > 오프라인 학습(offline learning)
                가용한 데이터를 모두 사용해 훈련
                일반적으로 이 방식은 시간과 자원을 많이 소모하므로 오프라인에서 수행
            > 모델 부패 (model rot) 또는 데이터 드리프트 (data drift)
                모델의 성능이 시간 경과에 따라 천천히 감소하는 경향
            > 전체 데이터셋을 사용해 훈련하는데 많은 시간이 소요
            > 전체 데이터셋을 사용해 훈련한다면 많은 컴퓨팅 자원이 필요
            > 자원이 제한된 시스템 (예: 스마트폰 또는 화성 탐사 로버)이 스스로 학습해야 할 때 많은 양의 훈련 데이터를 나르고
              나르고 매일 몇 시간씩 학습을 위해 많은 자원을 사용하면 심각한 문제 발생
                점진적으로 학습할 수 있는 알고리즘 사용하는 것이 효과적

        ● 온라인 학습 (online leaning)
            > 데이터를 순차적으로 한 개씩 또는 미니배치(mini-batch)라 부르는 작은 묶음 단위로 주입하여 시스템을 훈련.
            > 매 학습 단계가 빠르고 비용이 적게 들어 시스템은 데이터가 도착하는 대로 즉시 학습

                    1. 머신러닝 모델 훈련 - 2. 평가 - 3. 론칭 - 4. 실행 및 학습
                        - 온라인 학습에서는 모델을 훈련하고 제품에 론칭한 뒤에도 새로운 데이터가 들어오면 계속 학습

        ● 외부 메모리 학습 (out-of-core-learning)
            > 온라인 학습 알고리즘을 사용하여 컴퓨터 한 대의 메인 메모리에 들어갈 수 없는 아주 큰 데이터셋에서 모델을 훈련
            > 알고리즘이 데이터 일부를 읽어들이고 훈련 단계를 수행
            > 전체 데이터가 모두 적용될 때까지 이 과정을 반복

                    1. 문제 연구 - 2. 온라인 머신러닝 모델 훈련 - 3. 평가 - 4. 론칭/오류 분석
                        - 온라인 학습을 사용한 대량의 데이터 처리

        ● 학습률 (learning rate)
            > 온라인 학습 시스템에서 변화하는 데이터에 얼마나 빠르게 적응할 것인지의 파라미터
            > 학습률이 높으면 - 시스템이 데이터에 빠르게 적응하지만 예전 데이터를 금방 잊음
            > 학습률이 낮으면 - 시스템의 관성이 더 커져서 더 느리게 학습. 하지만 새로운 데이터에 있는 잡음이나 대표성 없는 데이터.포인트에 덜 민감.

        ● 온라인 학습에서 가장 큰 문제점
            > 시스템에 나쁜 데이터가 주입되었을 때 시스템 성능이 감소
            > 시스템을 면밀히 모니터링하고 성능 감소가 감지되면 즉각 학습을 중지

            * 머신러닝 프로젝트 과정 요약
                1. 데이터 분석 - 2. 모델 선택 - 3. 훈련 데이터로 모델을 훈련(학습 알고리즘이 비용 함수를 최소화하는 모델 파라미터를 찾음)
                4. 잘 일반화되기를 기대하면서 새로운 데이터에 모델을 적용해 예측 - 추론(inference)

        ● 충분하지 않은 양의 훈련 데이터
            > 머신러닝 알고리즘이 잘 작동하려면 데이터가 많아야 함.
            > 간단한 문제에서도 수천 개의 데이터가 필요하고 이미지나 음성 인식 같은 복잡한 문제라면 수백만 개가 필요
        ●대표성 없는 훈련 데이터
            > 일반화가 잘되려면 훈련 데이터가 일반화하고 싶은 새로운 사례를 잘 대표한는 것이 중요
            > 샘플이 작으면 샘플링 잡음(sampling noise, 우연에 의한 대표성 없는 데이터) 발생
            > 매우 큰 샘플도 표본 추출 방법이 잘못되면 대표성을 따지 못할 수 있음 - 샘플링 편향(sampling bias)
        ● 낮은 품질의 데이터
            > 훈련 데이터 정제가 필요한 경우
                : 일부 샘플이 이상치라는게 명확하면 간단히 해당 샘플들을 무시하거나 수동으로 잘못된 것을 고침
                : 일부 샘플에 특성 몇 개가 빠져있다면 ( 예: 고객 중 5%가 나이를 기록하지 않음 ) 이 특성을 모두 무시할지, 
                  이 샘플을 무시할지, 빠진 값을 채울지 ( 예: 평균 나이로 채움), 또는 이 특성을 넣은 모델과 제외한 모델을 따로 훈련시킬 것인지를 결정
        ● 관련없는 특성
            > 특성 공학 (feature engineering)
                : 특성 성택(feature selection) - 가지고 있는 특성 중에서 훈련에 가장 유용한 특성을 선택
                : 특성 추출(feature extration) - 특성을 결합하여 더 유용한 특성을 만듦
                : 데이터 수집 - 새로운 데이터를 수집해 새 특성을 만듦

        ● 훈련 데이터 과대적합
            > 모델이 훈련 데이터에는 잘 맞지만 일반성이 떨어짐.
        ● 훈련 데이터 과소적합
            > 모델이 너무 단순해서 데이터의 내재된 구조를 학습하지 못할 때 발생
                ㄴ 문제 해결
                    : 모델 파라미터가 더 많은 강력한 모델을 선택
                    : 학습 알고리즘에 더 좋은 특성을 제공 (특성공학)
                    : 모델의 제약을 줄임( 예: 규제 하이퍼파라미터를 감소시킴)


    







        
